{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Here we make use of ResNeXt and \"weakly supervised pre-training\", the ResNeXt-101 . See https://github.com/facebookresearch/WSL-Images for model information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "\n",
    "dir_csv = '../input/rsna-intracranial-hemorrhage-detection'\n",
    "dir_train_img = '../input/rsna-train-stage-1-images-png-224x/stage_1_train_png_224x'\n",
    "dir_test_img = '../input/rsna-test-stage-1-images-png-224x/stage_1_test_png_224x'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining some necessary parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "n_classes = 6\n",
    "n_epochs = 1\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installing some usful libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'apex' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/NVIDIA/apex && cd apex && pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'amp' from 'apex' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-3a9e20e834ff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Libraries\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mapex\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mamp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'amp' from 'apex' (unknown location)"
     ]
    }
   ],
   "source": [
    "# Libraries\n",
    "\n",
    "from apex import amp\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import pydicom\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from albumentations import Compose, ShiftScaleRotate, Resize\n",
    "from albumentations.pytorch import ToTensor\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.models as models\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining our dataset function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Functions\n",
    "\n",
    "class IntracranialDataset(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file, path, labels, transform=None):\n",
    "        \n",
    "        self.path = path\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        img_name = os.path.join(self.path, self.data.loc[idx, 'Image'] + '.png')\n",
    "        img = cv2.imread(img_name)   \n",
    "        \n",
    "        if self.transform:       \n",
    "            \n",
    "            augmented = self.transform(image=img)\n",
    "            img = augmented['image']   \n",
    "            \n",
    "        if self.labels:\n",
    "            \n",
    "            labels = torch.tensor(\n",
    "                self.data.loc[idx, ['epidural', 'intraparenchymal', 'intraventricular', 'subarachnoid', 'subdural', 'any']])\n",
    "            return {'image': img, 'labels': labels}    \n",
    "        \n",
    "        else:      \n",
    "            \n",
    "            return {'image': img}\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSVs\n",
    "\n",
    "train = pd.read_csv(os.path.join(dir_csv, 'stage_1_train.csv'))\n",
    "test = pd.read_csv(os.path.join(dir_csv, 'stage_1_sample_submission.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train out into row per image and save a sample\n",
    "\n",
    "train[['ID', 'Image', 'Diagnosis']] = train['ID'].str.split('_', expand=True)\n",
    "train = train[['Image', 'Diagnosis', 'Label']]\n",
    "train.drop_duplicates(inplace=True)\n",
    "train = train.pivot(index='Image', columns='Diagnosis', values='Label').reset_index()\n",
    "train['Image'] = 'ID_' + train['Image']\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing class imbalance in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking number of healthy and number of ill patients\n",
    "\n",
    "undersample_seed=0\n",
    "train[\"any\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stroing number of ill patients\n",
    "\n",
    "num_ill_patients = train[train[\"any\"]==1].shape[0]\n",
    "num_ill_patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting healthy patients equal to number of ill patients\n",
    "\n",
    "healthy_patients = train[train[\"any\"]==0].index.values\n",
    "healthy_patients_selection = np.random.RandomState(undersample_seed).choice(\n",
    "    healthy_patients, size=num_ill_patients, replace=False\n",
    ")\n",
    "len(healthy_patients_selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fusing together our selected healthy patients and the sick ones\n",
    "\n",
    "sick_patients = train[train[\"any\"]==1].index.values\n",
    "selected_patients = list(set(healthy_patients_selection).union(set(sick_patients)))\n",
    "len(selected_patients)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking healthy and new patients in the new dataset\n",
    "\n",
    "new_train = train.loc[selected_patients].copy()\n",
    "new_train[\"any\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some files didn't contain legitimate images, so we need to remove them\n",
    "\n",
    "png = glob.glob(os.path.join(dir_train_img, '*.png'))\n",
    "png = [os.path.basename(png)[:-4] for png in png]\n",
    "png = np.array(png)\n",
    "\n",
    "new_train = new_train[new_train['Image'].isin(png)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting train dataset to training and validation\n",
    "\n",
    "training , validation = train_test_split(new_train, test_size = 0.2, random_state =42)\n",
    "\n",
    "training.to_csv('train.csv', index=False)\n",
    "validation.to_csv('valid.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also prepare the test data\n",
    "\n",
    "test[['ID','Image','Diagnosis']] = test['ID'].str.split('_', expand=True)\n",
    "test['Image'] = 'ID_' + test['Image']\n",
    "test = test[['Image', 'Label']]\n",
    "test.drop_duplicates(inplace=True)\n",
    "\n",
    "test.to_csv('test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the predefined dataloader provided by pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loaders\n",
    "\n",
    "transform_train = Compose([\n",
    "    ShiftScaleRotate(),\n",
    "    ToTensor()\n",
    "])\n",
    "\n",
    "transform_test= Compose([\n",
    "    ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset = IntracranialDataset(\n",
    "    csv_file='train.csv', path=dir_train_img, transform=transform_train, labels=True)\n",
    "\n",
    "valid_dataset = IntracranialDataset(\n",
    "    csv_file='valid.csv', path=dir_train_img, transform=transform_train, labels=True)\n",
    "\n",
    "test_dataset = IntracranialDataset(\n",
    "    csv_file='test.csv', path=dir_test_img, transform=transform_test, labels=False)\n",
    "\n",
    "\n",
    "data_loader_train = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "data_loader_valid = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "data_loader_test = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot train example\n",
    "\n",
    "batch = next(iter(data_loader_train))\n",
    "fig, axs = plt.subplots(1, 5, figsize=(15,5))\n",
    "\n",
    "for i in np.arange(5):\n",
    "    \n",
    "    axs[i].imshow(np.transpose(batch['image'][i].numpy(), (1,2,0))[:,:,0], cmap=plt.cm.bone)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot validation example\n",
    "\n",
    "batch = next(iter(data_loader_valid))\n",
    "fig, axs = plt.subplots(1, 5, figsize=(15,5))\n",
    "\n",
    "for i in np.arange(5):\n",
    "    \n",
    "    axs[i].imshow(np.transpose(batch['image'][i].numpy(), (1,2,0))[:,:,0], cmap=plt.cm.bone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot test example\n",
    "\n",
    "batch = next(iter(data_loader_test))\n",
    "fig, axs = plt.subplots(1, 5, figsize=(15,5))\n",
    "\n",
    "for i in np.arange(5):\n",
    "    \n",
    "    axs[i].imshow(np.transpose(batch['image'][i].numpy(), (1,2,0))[:,:,0], cmap=plt.cm.bone)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading our ResNeXt-101 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "model = torch.hub.load('facebookresearch/WSL-Images', 'resnext101_32x16d_wsl')\n",
    "model.fc = torch.nn.Linear(2048, n_classes)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "plist = [{'params': model.parameters(), 'lr': 2e-3}]\n",
    "optimizer = optim.Adam(plist, lr=2e-3)\n",
    "\n",
    "model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model on the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    print('Epoch {}/{}'.format(epoch, n_epochs - 1))\n",
    "    print('-' * 10)\n",
    "\n",
    "    model.train()    \n",
    "    tr_loss = 0\n",
    "    \n",
    "    tk0 = tqdm(data_loader_train, desc=\"Iteration\")\n",
    "\n",
    "    for step, batch in enumerate(tk0):\n",
    "\n",
    "        inputs = batch[\"image\"]\n",
    "        labels = batch[\"labels\"]\n",
    "\n",
    "        inputs = inputs.to(device, dtype=torch.float)\n",
    "        labels = labels.to(device, dtype=torch.float)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "            scaled_loss.backward()\n",
    "\n",
    "        tr_loss += loss.item()\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    epoch_loss = tr_loss / len(data_loader_train)\n",
    "    print('Training Loss: {:.4f}'.format(epoch_loss))\n",
    "    \n",
    "    \n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    \n",
    "    tk1 = tqdm(data_loader_valid, desc=\"Iteration\")\n",
    "\n",
    "    for step, batch in enumerate(tk1):\n",
    "\n",
    "        inputs = batch[\"image\"]\n",
    "        labels = batch[\"labels\"]\n",
    "\n",
    "        inputs = inputs.to(device, dtype=torch.float)\n",
    "        labels = labels.to(device, dtype=torch.float)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        val_loss += loss.item()\n",
    "\n",
    "    epoch_loss = val_loss / len(data_loader_valid)\n",
    "    print('Validation Loss: {:.4f}'.format(epoch_loss))\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating model on test data set and getting the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model.eval()\n",
    "\n",
    "test_pred = np.zeros((len(test_dataset) * n_classes, 1))\n",
    "\n",
    "for i, x_batch in enumerate(tqdm(data_loader_test)):\n",
    "    \n",
    "    x_batch = x_batch[\"image\"]\n",
    "    x_batch = x_batch.to(device, dtype=torch.float)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        pred = model(x_batch)\n",
    "        \n",
    "        test_pred[(i * batch_size * n_classes):((i + 1) * batch_size * n_classes)] = torch.sigmoid(\n",
    "            pred).detach().cpu().reshape((len(x_batch) * n_classes, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing the results into a submission csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submission\n",
    "\n",
    "submission =  pd.read_csv(os.path.join(dir_csv, 'stage_1_sample_submission.csv'))\n",
    "submission = pd.concat([submission.drop(columns=['Label']), pd.DataFrame(test_pred)], axis=1)\n",
    "submission.columns = ['ID', 'Label']\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have to clean up since Kaggle limits the number of files that can be output from a kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /kaggle/working/apex\n",
    "!rm test.csv\n",
    "!rm train.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
